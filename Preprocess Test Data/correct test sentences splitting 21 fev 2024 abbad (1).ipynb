{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a3d1d1e-7023-4d88-a264-92ad69dc1cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abderrahman.skiredj/.conda/envs/skiredj_2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import string\n",
    "import pickle\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "arabic_letters = ['ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي']\n",
    "diacritics_list = ['ً', 'ٌ', 'ٍ', 'َ', 'ُ', 'ِ', 'ّ', 'ْ']\n",
    "strings_potentially_undiacritized = [\"ال\", \"ى\", \"ا\",\"ي\",\"و\",\"آ\",\"ٱ\", \"إ\", \"لل\", \"ٱل\", \"لِل\", \"لَل\", \"لا\"]\n",
    "strings_potentially_undiacritized = sorted([\"ال\", \"ى\", \"ا\",\"ي\",\"و\",\"آ\",\"ٱ\", \"إ\", \"لل\", \"ٱل\", \"لِل\", \"لَل\", \"لا\"], key = len, reverse = True)\n",
    "\n",
    "mapping_harakat = {'ً': 'فتحتان',\n",
    " 'ٌ': 'ضمتان',\n",
    " 'ٍ': 'كسرتان',\n",
    " 'َ': 'فتحة',\n",
    " 'ُ': 'ضمة',\n",
    " 'ِ': 'كسرة',\n",
    " 'ّ': 'شدة',\n",
    " 'ْ': 'سكون'}\n",
    "\n",
    "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "numbers = '0123456789'\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations + numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af374bb-fc98-4bba-b4ac-0fb35c0b9ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0849f06d-3c59-4f4e-ba9f-aff5c685a0db",
   "metadata": {},
   "source": [
    "cleaning:\n",
    "- if a word is partially diacritized while it shouldnt be: make -100 as a label to all its diacritics\n",
    "- for each sentence:\n",
    "    - if the nb tokens of preprocessed sentence < 512 ok\n",
    "    - else: split it recursively until each split when preprocessed is of length < 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306c866a-a720-42fe-ab58-fe36c967f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_special_chars(word):\n",
    "    return re.sub(f\"[{re.escape(punctuations_list)}]\", \"\", word)\n",
    "\n",
    "def undiacritize(original_text):\n",
    "    undiacritized_text = original_text\n",
    "    for haraka in diacritics_list:\n",
    "        undiacritized_text = undiacritized_text.replace(haraka, '')\n",
    "    return undiacritized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de93a4ee-062e-4d68-82ce-25a34e276148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_diac(word):\n",
    "    if any([x in word for x in diacritics_list]):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58a9a4e-1a70-4554-b989-73a0d0dea731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'بِسْمِ': Fully Diacritized\n",
      "'الحَمْدُ': Fully Diacritized\n",
      "'ذَهبَ': Partially Diacritized\n",
      "'في': Fully Diacritized\n",
      "'مُسْتَشْفى': Fully Diacritized\n",
      "'للهِ': Fully Diacritized\n",
      "'إِنْ': Fully Diacritized\n",
      "'آمِنْتُمْ': Fully Diacritized\n",
      "'اللهُ': Partially Diacritized\n",
      "'الحَمْد': Partially Diacritized\n",
      "'بِسْم': Partially Diacritized\n",
      "'اللّهُ': Fully Diacritized\n",
      "'صِحَّتَهَا': Fully Diacritized\n",
      "'الرَّافِعِيُّ': Fully Diacritized\n",
      "'تَمْلِيكَ': Fully Diacritized\n",
      "'يُبِيحُ': Fully Diacritized\n",
      "'كَسَوَادٍ': Fully Diacritized\n",
      "'بَكى': Fully Diacritized\n",
      "'بَكَى': Fully Diacritized\n",
      "'أَبُو': Fully Diacritized\n",
      "'حَتَّى': Fully Diacritized\n",
      "'صَلَّى': Fully Diacritized\n",
      "'وَالرَّهْنُ': Fully Diacritized\n",
      "'مَعْنًى': Fully Diacritized\n",
      "'لِلرَّدِّ': Fully Diacritized\n",
      "'وَ': Fully Diacritized\n",
      "'كَالطَّلْقِ': Fully Diacritized\n",
      "'كَالزَّمَانَةِ': Fully Diacritized\n",
      "'وَالدَّوَاءِ': Fully Diacritized\n",
      "'لِلسُّكْرِ': Fully Diacritized\n",
      "'مُذَكًّى': Fully Diacritized\n",
      "'تَعَالَى': Fully Diacritized\n",
      "'الْعِرَاقِيُّونَ': Fully Diacritized\n",
      "'تَعَالَى:': Fully Diacritized\n",
      "'الْحَضَرِيِّينَ': Fully Diacritized\n",
      "'فَوَلّى': Fully Diacritized\n",
      "'بِالْإِيلَاءِ': Fully Diacritized\n",
      "'صَلّى': Fully Diacritized\n",
      "'الْقُوَى': Fully Diacritized\n",
      "'إيضَاحُهُ': Fully Diacritized\n",
      "'عُبَيدٍ': Partially Diacritized\n",
      "'عَمْرٍو': Fully Diacritized\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Arabic letters and diacritics\n",
    "arabic_letters = ['ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي']\n",
    "diacritics_list = ['ً', 'ٌ', 'ٍ', 'َ', 'ُ', 'ِ', 'ّ', 'ْ']\n",
    "\n",
    "# Special cases and their automatic diacritization implications\n",
    "special_cases_multiletters = {\n",
    "    \"ال\": None,\n",
    "    \"لل\": None,\n",
    "    \"في\": None,\n",
    "    \"لا\": None,\n",
    "    \"إي\": None\n",
    "}\n",
    "\n",
    "special_cases_uniletters = {\n",
    "    \"إ\": 'ِ',  # Kasra\n",
    "    \"آ\": None,\n",
    "    \"ٱ\": None,\n",
    "    \"ا\": None,\n",
    "    \"ى\": None\n",
    "}\n",
    "\n",
    "very_special_word = \"عمرو\"\n",
    "\n",
    "def is_letter_diacritized(word, index):\n",
    "    \"\"\"Check if a letter at a given index is diacritized.\"\"\"\n",
    "    if index < len(word) - 1:\n",
    "        # Check if next character is a diacritic\n",
    "        return word[index + 1] in diacritics_list\n",
    "    return False\n",
    "\n",
    "def check_special_cases(word, index):\n",
    "    \"\"\"Check for special cases that do not require diacritization.\"\"\"\n",
    "    '''for case, diacritic in special_cases_multiletters.items():\n",
    "        if word.startswith(case, index):\n",
    "            return True, len(case)\n",
    "    for case, diacritic in special_cases_uniletters.items():\n",
    "        if word.startswith(case, index):\n",
    "            return True, len(case)'''\n",
    "\n",
    "    for case, diacritic in special_cases_multiletters.items():\n",
    "        if undiacritize(word[index:]).startswith(case):\n",
    "            len_case = len(case)\n",
    "            if word[index+1] in diacritics_list:\n",
    "                len_case += 1\n",
    "            return True, len_case\n",
    "\n",
    "    if index < len(word) - 2 and word[index + 1] in [\"ا\", \"ى\"] and word[index + 2]==\"ل\":\n",
    "        # Letter followed by \"ا\" or \"ى\", considered diacritized\n",
    "        return True, 3\n",
    "    if index < len(word) - 3 and word[index + 1]=='َ' and word[index + 2] in [\"ا\", \"ى\"] and word[index + 3]==\"ل\":\n",
    "        return True, 4\n",
    "    if index < len(word) - 4 and word[index + 1]=='َ' and  word[index + 2]== 'ّ' and word[index + 3] in [\"ا\", \"ى\"] and word[index + 4]==\"ل\":\n",
    "        return True, 5\n",
    "    if index < len(word) - 4 and word[index + 1]== 'ّ' and  word[index + 2]=='َ' and word[index + 3] in [\"ا\", \"ى\"] and word[index + 4]==\"ل\":\n",
    "        return True, 5\n",
    "\n",
    "    if index < len(word) - 1 and word[index + 1] in [\"ا\", \"ى\"]:\n",
    "        # Letter followed by \"ا\" or \"ى\", considered diacritized\n",
    "        return True, 2\n",
    "    if index < len(word) - 2 and word[index + 1]=='َ' and word[index + 2] in [\"ا\", \"ى\"]:\n",
    "        return True, 3\n",
    "    if index < len(word) - 2 and word[index + 1]=='ً' and word[index + 2] in [\"ا\", \"ى\"]:\n",
    "        return True, 3\n",
    "    if index < len(word) - 3 and word[index + 1]=='َ' and  word[index + 2]== 'ّ' and word[index + 3] in [\"ا\", \"ى\"]:\n",
    "        return True, 4\n",
    "    if index < len(word) - 3 and word[index + 1]== 'ّ' and  word[index + 2]=='َ' and word[index + 3] in [\"ا\", \"ى\"]:\n",
    "        return True, 4\n",
    "\n",
    "    if index < len(word) - 3 and word[index + 1]=='ً' and  word[index + 2]== 'ّ' and word[index + 3] in [\"ا\", \"ى\"]:\n",
    "        return True, 4\n",
    "    if index < len(word) - 3 and word[index + 1]== 'ّ' and  word[index + 2]=='ً' and word[index + 3] in [\"ا\", \"ى\"]:\n",
    "        return True, 4\n",
    "\n",
    "    if index > 1 and word[index -1] in ['َ' ,  'ّ'] and word[index] == \"ا\":\n",
    "        return True, 1\n",
    "        \n",
    "    if index < len(word) - 2 and word[index + 1]=='ِ' and word[index + 2]==\"ي\":\n",
    "        return True, 3\n",
    "    if index < len(word) - 3 and word[index + 1]=='ِ' and word[index + 2]== 'ّ' and word[index + 3]==\"ي\":\n",
    "        return True, 4\n",
    "    if index < len(word) - 3 and word[index + 1]==  'ّ' and word[index + 2]=='ِ' and word[index + 3]==\"ي\":\n",
    "        return True, 4\n",
    "\n",
    "    if index > 1 and word[index -1] in [ 'ِ' ,  'ّ'] and word[index] == \"ي\":\n",
    "        return True, 1\n",
    "        \n",
    "    if index < len(word) - 2 and word[index + 1]== 'ُ' and word[index + 2]==\"و\":\n",
    "        return True, 3\n",
    "    if index < len(word) - 3 and word[index + 1]== 'ُ' and word[index + 2]== 'ّ' and word[index + 3]==\"و\":\n",
    "        return True, 4\n",
    "    if index < len(word) - 3 and word[index + 1]== 'ّ' and word[index + 2]==  'ُ' and word[index + 3]==\"و\":\n",
    "        return True, 4\n",
    "\n",
    "    if index > 1 and word[index -1] in [ 'ُ', 'ّ' ]and word[index] == \"و\":\n",
    "        return True, 1\n",
    "\n",
    "    for case, diacritic in special_cases_uniletters.items():\n",
    "        if undiacritize(word[index:]).startswith(case):\n",
    "            return True, len(case)\n",
    "    if undiacritize(word) == very_special_word and word[index] == \"و\":\n",
    "        return True, 1\n",
    "    return False, 0\n",
    "\n",
    "def is_fully_diacritized(word):\n",
    "    i = 0\n",
    "    while i < len(word):\n",
    "        if word[i] in arabic_letters:\n",
    "            # Check if the current letter is within special cases\n",
    "            special_case_found, jump = check_special_cases(word, i)\n",
    "            if special_case_found:\n",
    "                i += jump  # Skip the letters covered by the special case\n",
    "                continue\n",
    "            elif not is_letter_diacritized(word, i):\n",
    "                return False  # Found an undiacritized letter outside special cases\n",
    "        i += 1\n",
    "    return True\n",
    "\n",
    "# Examples to test the function\n",
    "words = [\"بِسْمِ\", \"الحَمْدُ\", \"ذَهبَ\", \"في\", \"مُسْتَشْفى\", \"للهِ\", \"إِنْ\", \"آمِنْتُمْ\", \"اللهُ\", \"الحَمْد\", \"بِسْم\", \"اللّهُ\"] +  [\"صِحَّتَهَا\", \"الرَّافِعِيُّ\", \"تَمْلِيكَ\", \"يُبِيحُ\", \"كَسَوَادٍ\"] + [\"بَكى\", \"بَكَى\"] + ['أَبُو','حَتَّى',  'صَلَّى'] + ['وَالرَّهْنُ', \"مَعْنًى\", \"لِلرَّدِّ\", \"وَ\", \"كَالطَّلْقِ\", \"كَالزَّمَانَةِ\",  \"وَالدَّوَاءِ\", \"لِلسُّكْرِ\"] + [\"مُذَكًّى\", \"تَعَالَى\", \"الْعِرَاقِيُّونَ\", \"تَعَالَى:\", \"الْحَضَرِيِّينَ\", \"فَوَلّى\", \"بِالْإِيلَاءِ\", \"صَلّى\", \"الْقُوَى\"]\n",
    "words = words + [\"إيضَاحُهُ\", \"عُبَيدٍ\", \"عَمْرٍو\"]\n",
    "results = {word: is_fully_diacritized(word) for word in words}\n",
    "\n",
    "for word, result in results.items():\n",
    "    print(f\"'{word}': {'Fully Diacritized' if result else 'Partially Diacritized'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3289b27-5e72-420d-ad56-2ed7ea552cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6fc23-daff-482c-99b3-4025fce75d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78c1b4af-2485-43dd-97de-483efc877c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4c8fe1-1e6a-4969-a462-84d7bb7b5a1a",
   "metadata": {},
   "source": [
    "1- take the test sentences, transform them to tokens, labels\n",
    "\n",
    "2- keep the sentences with len input ids < 512\n",
    "\n",
    "3- save the sentences with longer input ids\n",
    "\n",
    "4- for PTCAD(0) split them and save them apart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39ec9d47-ad11-4f7c-9311-2101b1fa5660",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tashkeela_test_006.txt',\n",
       " 'tashkeela_test_001.txt',\n",
       " 'tashkeela_test_009.txt',\n",
       " 'tashkeela_test_013.txt',\n",
       " 'tashkeela_test_014.txt',\n",
       " 'tashkeela_test_005.txt',\n",
       " 'tashkeela_test_011.txt',\n",
       " 'tashkeela_test_008.txt',\n",
       " 'tashkeela_test_012.txt',\n",
       " 'tashkeela_test_015.txt',\n",
       " 'tashkeela_test_004.txt',\n",
       " 'tashkeela_test_003.txt',\n",
       " 'tashkeela_test_007.txt',\n",
       " 'tashkeela_test_010.txt',\n",
       " 'tashkeela_test_002.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('tashkeela full test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed3a3594-1abf-4b29-aa57-fdca3f12c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = []\n",
    "for x in os.listdir('tashkeela full test'):\n",
    "    file = open(os.path.join('tashkeela full test',x), \"r\")\n",
    "    test_sentences.extend(file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e45450-51e8-47f8-8b49-cc15da55c954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30f92773-52b7-48e4-bf7d-14f96be34819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diacritic_of(ar_letter_tuple, word):\n",
    "    ar_letter, index = ar_letter_tuple\n",
    "    diacritics = []\n",
    "    i = index + 1\n",
    "    while i < len(word):\n",
    "        if word[i] in diacritics_list:\n",
    "            diacritics.append(word[i])\n",
    "        else:\n",
    "            break\n",
    "        i += 1\n",
    "    return diacritics\n",
    "    \n",
    "def bert_transform_word(word):\n",
    "    # Get the list of Arabic letters in the word\n",
    "    transformed_word = {\"tokens\":[], \"labels\":[]}\n",
    "    ar_letters = [c for c in word if c in arabic_letters]\n",
    "    if not is_fully_diacritized(word):\n",
    "        transformed_word['tokens'] = [undiacritize(word)]+len(ar_letters)*['[MASK]']\n",
    "        transformed_word['labels'] = ['X'] + len(ar_letters)*['X']\n",
    "        return transformed_word\n",
    "    if len(ar_letters) <= 0:\n",
    "        transformed_word['tokens'] = [word]\n",
    "        transformed_word['labels'] = ['X']\n",
    "        return transformed_word\n",
    "    ar_letters = [(word[i], i) for i in range(len(word)) if word[i] in arabic_letters]\n",
    "    # Get the list of diacritics associated with each Arabic letter in the word\n",
    "    diacritics_list_word = [diacritic_of(ar_letter_tuple, word) for ar_letter_tuple in ar_letters]\n",
    "    result_list = []\n",
    "    for diacritics in diacritics_list_word:\n",
    "        if diacritics == []:\n",
    "            result_list.append(['تطويل'])\n",
    "        else:\n",
    "            result_list.append([mapping_harakat[diacritic] for diacritic in diacritics])\n",
    "    transformed_word['tokens'].append(undiacritize(word))\n",
    "    for haraka in result_list:\n",
    "        transformed_word['tokens'].append('[MASK]')\n",
    "    transformed_word['labels'].append('X')\n",
    "    transformed_word['labels'].extend([' '.join(x) for x in result_list])\n",
    "    return transformed_word\n",
    "    \n",
    "def bert_transform_sentence(sentence):\n",
    "    transformed_sentence = {\"tokens\":[], \"labels\":[]}\n",
    "    words = sentence.split(' ')\n",
    "    for word in words:\n",
    "        transformed_word = bert_transform_word(word)\n",
    "        transformed_sentence['tokens'].extend(transformed_word['tokens'])\n",
    "        transformed_sentence['labels'].extend(transformed_word['labels'])\n",
    "    return transformed_sentence\n",
    "\n",
    "def bert_seq_length_of(s, tokenizer):\n",
    "    return len(tokenizer(''.join(bert_transform_sentence(s)['tokens']))['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e73cdb2-1adb-4970-bc19-803330c7fed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'tokens': ['و', '[MASK]'], 'labels': ['X', 'فتحة']},\n",
       " {'tokens': ['ك', '[MASK]'], 'labels': ['X', 'فتحة']})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_transform_word(\"وَ\"), bert_transform_word(\"كَ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbd5d6ee-ae57-4555-a672-f135cb541519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('AbderrahmanSkiredj1/arabertv02_tashkeel_fadel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d244e376-484b-4c1a-91ec-d6d4ded8601f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "149872"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_test_sentences = [x for x in test_sentences if bert_seq_length_of(x, tokenizer)<511]\n",
    "len(short_test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d0d331f-bcbc-4207-9ef6-b6c8f4ed4bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_sentences = [x for x in test_sentences if x not in short_test_sentences]\n",
    "len(long_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d70db41-a29d-4fa6-9d3e-882ff9e8567f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d63f8d87-2ccc-4712-920d-23d04a6081dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "short_test_sentences_transformed = [bert_transform_sentence(sentence) for sentence in short_test_sentences]\n",
    "#short_test_sentences_transformed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d11d751a-c325-408d-a6ca-ef7719ea3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_test_sentences_transformed = [bert_transform_sentence(sentence) for sentence in long_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6a529-5d6a-45de-ad6f-926b6400bd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "850e4bcc-447f-485c-8a4a-1c53f522a457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1092"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice\n",
    "len(choice(long_test_sentences_transformed)['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf21daa2-edcb-4f29-b2e3-cf5fc0b5da6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'labels'],\n",
       "    num_rows: 128\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset_dict = {\"tokens\": [x[\"tokens\"] for x in long_test_sentences_transformed], \"labels\": [x[\"labels\"] for x in long_test_sentences_transformed]}\n",
    "dat = Dataset.from_dict(dataset_dict)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86ec2ecb-0aa6-46a7-b0a7-a9aa9256702c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'labels'],\n",
       "    num_rows: 149872\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset_dict = {\"tokens\": [x[\"tokens\"] for x in short_test_sentences_transformed], \"labels\": [x[\"labels\"] for x in short_test_sentences_transformed]}\n",
    "dat = Dataset.from_dict(dataset_dict)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "551150d9-548c-4fe5-8b18-7cfb1b14637f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'labels'],\n",
       "    num_rows: 149872\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48b0f583-e835-4869-b8b1-125b247d9796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 149872/149872 [00:00<00:00, 707406.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dat.save_to_disk(\"test_datasets_processed/abbad_test_short_sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "587d2431-d8b5-4cb6-93ac-f008c058d172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 128/128 [00:00<00:00, 20565.83 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dat.save_to_disk(\"test_datasets_processed/abbad_test_long_sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a42ae88a-0c85-4e0e-af8c-31b9bc54870c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 2202/2202 [00:00<00:00, 183458.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#dat.save_to_disk(\"test_datasets_processed/fadel_test_short_sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd142dcf-b633-4d88-b66c-ef3acc1a62c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 511\n",
    "def is_sentence_of_acceptable_length(s):\n",
    "    return bert_seq_length_of(s, tokenizer) < MAX_LENGTH\n",
    "\n",
    "def split_sentence(sentence):\n",
    "    sub_sentences = []\n",
    "    current_sentence = \"\"\n",
    "    for word in sentence.split(\" \"):\n",
    "        if is_sentence_of_acceptable_length(current_sentence + \" \" + word):\n",
    "            current_sentence += \" \" + word\n",
    "        else:\n",
    "            sub_sent_to_append = current_sentence.strip()\n",
    "            sub_sentences.append(sub_sent_to_append)\n",
    "            current_sentence = word\n",
    "    sub_sentences.append(current_sentence.strip())\n",
    "    return sub_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fa53aaf-40af-433b-acb6-056fbd34f325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 262)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_sentences_splitted = [split_sentence(x) for x in long_sentences]\n",
    "long_sentences_splitted = [x for y in long_sentences_splitted for x in y]\n",
    "len(long_sentences), len(long_sentences_splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71fb3909-761b-4674-aff1-dcc9487e2775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "وَقَوْلُهُ حَتَّى قَالَ بَعْضُهُمْ إنَّهُ فِي شَرْحِ المُهَذَّبِ صَحَّحَ هِبَةَ المَدِينِ وَمِنْ أَيْنَ لَهُ ذَلِكَ وَفِي أَيِّ مَوْضِعٍ صَحَّحَهُ يُقَالُ عَلَيْهِ هَذَا مِمَّا يُتَعَجَّبُ مِنْهُ أَيْضًا لِمَا مَرَّ مَبْسُوطًا أَنَّهُ نَقَلَهُ عَنْ الشَّاشِيِّ وَسَكَتَ عَلَيْهِ وَأَنَّ مَوْضُوعَ شَرْحِهِ لِلْمُهَذَّبِ الَّذِي هُوَ مُتَتَبِّعٌ فِيهِ لِكَلَامِ الأَصْحَابِ أَنَّ سُكُوتَهُ عَلَى الحُكْمِ فِيهِ إنَّمَا هُوَ لِارْتِضَائِهِ لَهُ وَأَنَّ الغَالِبَ أَنَّ الضَّعِيفَ إنَّمَا يَقِيسُ عَلَى مَا يُوَافِقُهُ عَلَيْهِ الأَصَحُّ فَهَذَا كُلُّهُ يُؤَيِّدُ القَائِلَ بِأَنَّهُ صَحَّحَهُ أَوْ جَزَمَ بِهِ السَّابِقُ عَنْ الإِسْنَوِيِّ وَزَعَمَ المُعْتَرِضُ أَنَّ كَلَامَهُ فِيهِ تَزْيِيفٌ لِكَلَامِ الشَّاشِيِّ غَيْرُ صَحِيحٍ كَمَا مَرَّ بَيَانُهُ وَقَوْلُهُ وَالعَجَبُ أَنَّ المُفَرِّقِينَ فِي التَّيَمُّم\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "a = choice(long_sentences_splitted)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c037add-7943-4477-9e65-d1cbe44a82a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_sentences_splitted.index(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6507c640-40f5-43b5-8971-eea26f5331d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'أَقُولُ : وَمَعَ ذَلِكَ فَيُمْكِنُ تَوْجِيهُهُ بِأَنَّ قَوْلَهُ لِمَالِكِهَا بَدَلٌ مِنْ لِهَذِهِ الدَّابَّةِ ( قَوْلُهُ : فَإِنْ أَرَادَ غَيْرَهُ ) أَيْ كَأَنْ قَالَ : أَرَدْت مَنْ انْتَقَلَتْ مِنْهُ إلَى مَنْ هِيَ تَحْتَ يَدِهِ الْآنَ وَإِنْ طَالَتْ مُدَّةُ كَوْنِهَا فِي مِلْكِ مَنْ هِيَ تَحْتَ يَدِهِ ( قَوْلُهُ : وَلَوْ لَمْ يَقُلْ لِمَالِكِهَا ) بَلْ قَالَ عَلَيَّ بِسَبَبِ هَذِهِ الدَّابَّةِ ( قَوْلُهُ : لِمَالِكِهَا حَالًّا ) أَيْ بَلْ وَلَا لِمَالِكِهَا مُطْلَقًا لِجَوَازِ أَنْ تَكُونَ فِي يَدِهِ بِنَحْوِ إعَارَةٍ أَوْ غَصْبٍ فَأَتْلَفَتْ شَيْئًا فَهُوَ مَضْمُونٌ عَلَيْهِ لِمَالِكِهِ لَا لِمَالِكِهَا فَيُسْتَفْسَرُ وَيُعْمَلُ بِتَفْسِيرِهِ ا ه سم عَلَى حَجّ عَنْ شَرْحِ الْبَهْجَةِ بِالْمَعْنَى ( قَوْلُهُ : لِأَنَّهَا ) أَيْ الْبَلَدِ وَقَوْلُهُ ثُمَّ اُسْتُرِقَّ أَيْ الْحَرْبِيُّ ( قَوْلُهُ : فَإِنْ عَتَقَ فَلَهُ'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_sentences_splitted[236]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fdcc57-99a4-4065-adf8-045a06c7806a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6add9817-dab6-4556-8587-508cafcbb589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'labels'],\n",
       "    num_rows: 262\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_test_sentences_splitted_transformed = [bert_transform_sentence(sentence) for sentence in long_sentences_splitted]\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset_dict = {\"tokens\": [x[\"tokens\"] for x in long_test_sentences_splitted_transformed], \"labels\": [x[\"labels\"] for x in long_test_sentences_splitted_transformed]}\n",
    "dat = Dataset.from_dict(dataset_dict)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39a0732d-9d88-438a-b863-dc198f55f3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'labels'],\n",
       "    num_rows: 262\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5afa76d7-f4a4-4c60-b39f-5bed1fd6ec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 262/262 [00:00<00:00, 46577.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dat.save_to_disk('test_datasets_processed/abbad_test_long_sentences_splitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cda6eb3-73d4-4594-b7fd-1cc82048f284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'labels'],\n",
       "    num_rows: 150134\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk, concatenate_datasets\n",
    "dat2 = load_from_disk('test_datasets_processed/abbad_test_short_sentences')\n",
    "daat = concatenate_datasets([dat2, dat])\n",
    "daat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb321e89-e2a3-49fe-915f-807f5d596fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 150134/150134 [00:00<00:00, 561997.60 examples/s]\n"
     ]
    }
   ],
   "source": [
    "daat.save_to_disk('test_datasets_processed/abbad_test_sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ac65e32-f996-487b-99d0-eea6e5f4b9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abderrahman.skiredj/.conda/envs/skiredj_2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 3/3 [00:00<00:00, 15.94ba/s]\u001b[A\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  5.67ba/s]\u001b[A\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 3/3 [00:00<00:00,  8.01ba/s]\u001b[A\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "short = load_from_disk('test_datasets_processed/fadel_test_short_sentences')\n",
    "long = load_from_disk('test_datasets_processed/fadel_test_long_sentences_splitted')\n",
    "all = load_from_disk('test_datasets_processed/fadel_test_sentences')\n",
    "short.push_to_hub('AbderrahmanSkiredj1/fadel_test_short_sentences_as_token_classif', private = True)\n",
    "long.push_to_hub('AbderrahmanSkiredj1/fadel_test_long_sentences_splitted_as_token_classif', private = True)\n",
    "all.push_to_hub('AbderrahmanSkiredj1/fadel_test_sentences_sizeok_as_token_classif', private = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211c437-149c-4d63-82dd-366f437e5f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e4515df-5158-4f49-a7c2-f8147fa545da",
   "metadata": {},
   "source": [
    "## Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78b2863-8e67-452e-b7db-3fdc8357e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"الْحَضَرِيِّينَ\"\n",
    "i = 0\n",
    "while i < len(word):\n",
    "    if word[i] in arabic_letters:\n",
    "        print(word[i])\n",
    "        # Check if the current letter is within special cases\n",
    "        special_case_found, jump = check_special_cases(word, i)\n",
    "        print(special_case_found, jump, i)\n",
    "        if special_case_found:\n",
    "            i += jump  # Skip the letters covered by the special case\n",
    "            continue\n",
    "        elif not is_letter_diacritized(word, i):\n",
    "            print(False)  # Found an undiacritized letter outside special cases\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36a78104-ade0-41e4-b6c8-4ccf381b111e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"صِحَّتَهَا\", \"الرَّافِعِيُّ\", \"تَمْلِيكَ\", \"يُبِيحُ\", \"كَسَوَادٍ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97b536d5-da90-403e-98b3-3f141e6484c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tocheck = [x for x in short_test_sentences_transformed if any([contain_diac(y) for y in x[\"tokens\"]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e4e53c2-69e3-4ec6-8cd3-78f25dbcb2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tocheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb9a4783-1375-402e-9957-c19c5ac28852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['وَالرَّهْنُ', 'مَعْنًى']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['وَالرَّهْنُ', \"مَعْنًى\", \"لِلرَّدِّ\", \"وَ\", \"كَالطَّلْقِ\", \"كَالزَّمَانَةِ\",  \"وَالدَّوَاءِ\", \"لِلسُّكْرِ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "763e3162-1fe2-4f05-827c-7ed99e822e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['الْإِيضَاحِ']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"الْإِيضَاحِ\", \"تَعَالَى\", \"إيثَارُهُ\", \"اللَّيَالِي\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd4109-5729-4ff1-976d-7273fe963120",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"مُذَكًّى\", \"تَعَالَى\", \"الْعِرَاقِيُّونَ\", \"تَعَالَى:\", \"الْحَضَرِيِّينَ\", \"فَوَلّى\", \"بِالْإِيلَاءِ\", \"صَلّى\", \"الْقُوَى\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd87cc3-1982-4076-b0b8-3001e1014b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"إيضَاحُهُ\", \"عُبَيدٍ\", \"عَمْرٍو\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "099cd33d-fcd7-49cb-b337-24a1c80c74ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "عَمْرٍو\n",
      "عَمْرٌو\n",
      "عَمْرٍو\n",
      "عَمْرٌو\n",
      "وَلِعَمْرٍو\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "chosen = choice(tocheck)\n",
    "print(\"\\n\".join([x for x in chosen['tokens'] if contain_diac(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a1978d2-0e22-445e-a2c9-def3bcddfd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['(',\n",
       "  'وَ',\n",
       "  ')',\n",
       "  'إن',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'رجع',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'بعضهم',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '(',\n",
       "  'بعد',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'حد',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  ')',\n",
       "  'مشهود',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'عليه',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '(',\n",
       "  'يحد',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'راجع',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  ')',\n",
       "  'عن',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'شهادته',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '(',\n",
       "  'فقط',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  ')',\n",
       "  '؛',\n",
       "  'أي',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  ':',\n",
       "  'دون',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'من',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'لم',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'يرجع',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '؛',\n",
       "  'لأن',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'إقامة',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'الحد',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'كحكم',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'الحاكم',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '؛',\n",
       "  'فلا',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'ينقض',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'برجوع',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'الشهود',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'أو',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'بعضهم',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '،',\n",
       "  'لكن',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'يحد',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'الراجع',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'لإقراره',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'بالقذف',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '،',\n",
       "  'فيلزمه',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'حده',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'إذا',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'كان',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'الحد',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'جلدا',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'أو',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'رجما',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'وطالبه',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'به',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'قبل',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'موته',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '،',\n",
       "  'فيحد',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'بطلب',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  'الورثة',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '[MASK]',\n",
       "  '.(',\n",
       "  '18',\n",
       "  '/',\n",
       "  '145',\n",
       "  ')\\n'],\n",
       " 'labels': ['X',\n",
       "  'X',\n",
       "  'X',\n",
       "  'X',\n",
       "  'تطويل',\n",
       "  'سكون',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'فتحة',\n",
       "  'فتحة',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'ضمة',\n",
       "  'ضمة',\n",
       "  'سكون',\n",
       "  'X',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'فتحة',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'شدة كسرتان',\n",
       "  'X',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'ضمة',\n",
       "  'تطويل',\n",
       "  'كسرتان',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'كسرة',\n",
       "  'X',\n",
       "  'X',\n",
       "  'ضمة',\n",
       "  'فتحة',\n",
       "  'شدة ضمة',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'تطويل',\n",
       "  'كسرة',\n",
       "  'ضمتان',\n",
       "  'X',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'فتحة',\n",
       "  'تطويل',\n",
       "  'فتحة',\n",
       "  'كسرة',\n",
       "  'كسرة',\n",
       "  'X',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'X',\n",
       "  'X',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'X',\n",
       "  'X',\n",
       "  'ضمة',\n",
       "  'تطويل',\n",
       "  'فتحة',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'كسرة',\n",
       "  'سكون',\n",
       "  'X',\n",
       "  'X',\n",
       "  'كسرة',\n",
       "  'فتحة',\n",
       "  'شدة فتحة',\n",
       "  'X',\n",
       "  'تطويل',\n",
       "  'فتحة',\n",
       "  'تطويل',\n",
       "  'فتحة',\n",
       "  'فتحة',\n",
       "  'X',\n",
       "  'تطويل',\n",
       "  'سكون',\n",
       "  'فتحة',\n",
       "  'شدة كسرة',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'ضمة',\n",
       "  'سكون',\n",
       "  'كسرة',\n",
       "  'X',\n",
       "  'تطويل',\n",
       "  'سكون',\n",
       "  'فتحة',\n",
       "  'تطويل',\n",
       "  'كسرة',\n",
       "  'كسرة',\n",
       "  'X',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'فتحة',\n",
       "  'تطويل',\n",
       "  'X',\n",
       "  'ضمة',\n",
       "  'سكون',\n",
       "  'فتحة',\n",
       "  'ضمة',\n",
       "  'X',\n",
       "  'كسرة',\n",
       "  'ضمة',\n",
       "  'ضمة',\n",
       "  'تطويل',\n",
       "  'كسرة',\n",
       "  'X',\n",
       "  'تطويل',\n",
       "  'تطويل',\n",
       "  'شدة ضمة',\n",
       "  'ضمة',\n",
       "  'تطويل',\n",
       "  'كسرة',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'كسرة',\n",
       "  'كسرة',\n",
       "  'سكون',\n",
       "  'X',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'كسرة',\n",
       "  'سكون',\n",
       "  'X',\n",
       "  'ضمة',\n",
       "  'فتحة',\n",
       "  'شدة ضمة',\n",
       "  'X',\n",
       "  'تطويل',\n",
       "  'تطويل',\n",
       "  'شدة فتحة',\n",
       "  'تطويل',\n",
       "  'كسرة',\n",
       "  'ضمة',\n",
       "  'X',\n",
       "  'كسرة',\n",
       "  'كسرة',\n",
       "  'سكون',\n",
       "  'فتحة',\n",
       "  'تطويل',\n",
       "  'كسرة',\n",
       "  'كسرة',\n",
       "  'X',\n",
       "  'كسرة',\n",
       "  'تطويل',\n",
       "  'سكون',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'كسرة',\n",
       "  'X',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'فتحة',\n",
       "  'ضمة',\n",
       "  'ضمة',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'شدة ضمة',\n",
       "  'ضمة',\n",
       "  'X',\n",
       "  'تطويل',\n",
       "  'فتحة',\n",
       "  'تطويل',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'تطويل',\n",
       "  'فتحة',\n",
       "  'X',\n",
       "  'تطويل',\n",
       "  'سكون',\n",
       "  'فتحة',\n",
       "  'شدة ضمة',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'فتحتان',\n",
       "  'تطويل',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'فتحتان',\n",
       "  'تطويل',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'فتحة',\n",
       "  'تطويل',\n",
       "  'فتحة',\n",
       "  'فتحة',\n",
       "  'ضمة',\n",
       "  'X',\n",
       "  'كسرة',\n",
       "  'كسرة',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'فتحة',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'سكون',\n",
       "  'كسرة',\n",
       "  'كسرة',\n",
       "  'X',\n",
       "  'X',\n",
       "  'فتحة',\n",
       "  'ضمة',\n",
       "  'فتحة',\n",
       "  'شدة ضمة',\n",
       "  'X',\n",
       "  'كسرة',\n",
       "  'فتحة',\n",
       "  'فتحة',\n",
       "  'كسرة',\n",
       "  'X',\n",
       "  'تطويل',\n",
       "  'سكون',\n",
       "  'فتحة',\n",
       "  'فتحة',\n",
       "  'فتحة',\n",
       "  'كسرة',\n",
       "  'X',\n",
       "  'X',\n",
       "  'X',\n",
       "  'X',\n",
       "  'X']}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7320a295-5075-45f1-9bac-7de38f051886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_fully_diacritized('وَ'), is_fully_diacritized(\"وَ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
